{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ea836eb",
   "metadata": {},
   "source": [
    "<!-- This notebook is created by Siu Pui Cheung, 09/02/2024 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4106c544",
   "metadata": {},
   "source": [
    "## 0. Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "859a7e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os, sys, numpy as np, pandas as pd, tkinter as tk\n",
    "from tkinter import filedialog, PhotoImage\n",
    "import mediapipe as mp\n",
    "import threading\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "plt.switch_backend('PDF') # Setup for matplotlib to use PDF backend\n",
    "\n",
    "# Initialize mediapipe pose class\n",
    "mp_pose, pose_landmark = mp.solutions.pose, mp.solutions.pose.PoseLandmark\n",
    "landmarks_to_draw = list(mp_pose.PoseLandmark)\n",
    "posture_data, buffer, sml_buffer, sign, run, stop_evaluation = {}, 10, 5, \"| \", True, False\n",
    "\n",
    "joint_angles_df = pd.DataFrame()\n",
    "body_labels =[ ['Left shoulder', 'Right Shoulder', 'Left Elbow', 'Right Elbow', 'Left Wrist', 'Right Wrist', 'Left Upper Body', 'Right Upper Body', 'Left Knee', 'Right Knee', 'Left Low Limb', 'Right Low Limb', 'Shoulder Midpoint', 'Central Vertical Midpoint'],\n",
    "    ['Left Shoulder', 'Right Shoulder', 'Left Elbow', 'Right Elbow', 'Left Upper Body', 'Right Upper Body', 'Left Knee', 'Right Knee', 'Left Low Limb', 'Right Low Limb', 'Left Neck', ' Right Neck', 'Left Hip', 'Right Hip', 'Left Ankle Flexion', 'Right Ankle Flexion'],\n",
    "    ['Shoulder Angle Difference', 'Elbow Angle Difference', 'Hip Angle Difference'],\n",
    "    ['Shoulder Angle Difference', 'Shoulder Midpoint X-coordinate', 'Central Vertical Line X-coordinate'],\n",
    "    ['Ear Angle Difference', 'Shoulder Angle Difference', 'Hip Angle Difference', 'Knee Angle Difference', 'Ankle Angle Difference'],\n",
    "    ['Left Shoulder Angle', 'Left Low Limb Angle']]\n",
    "\n",
    "def gui(options):\n",
    "    # Use os.getcwd() as a fallback when __file__ is not defined\n",
    "    if getattr(sys, 'frozen', False):\n",
    "        application_path = sys._MEIPASS  # When running as exe, the path is different.\n",
    "    else:\n",
    "        application_path = os.getcwd()  # Fallback to current working directory\n",
    "\n",
    "    # Adjust the path to the background image using application_path\n",
    "    bg_image_path = os.path.join(application_path, 'image/bg.png')  # Adjust this line for your images\n",
    "\n",
    "    dialog = tk.Toplevel() # Initialize dialog window\n",
    "    dialog.title(\"AI Posture Evaluator\")\n",
    "\n",
    "    # Load and place background image using the adjusted path\n",
    "    bg_image = PhotoImage(file=bg_image_path).subsample(2, 2)\n",
    "    tk.Label(dialog, image=bg_image).place(x=0, y=0, relwidth=1, relheight=1)\n",
    "    dialog.bg_image = bg_image  # Keep a reference\n",
    "    tk.Label(dialog, text=\"Â© 2024 E.C.| v1.1.1\", font=(\"Helvetica\", 5)).place(x=0, y=bg_image.height() - 10)\n",
    "    dialog.geometry(f\"{bg_image.width()}x{bg_image.height()}\")\n",
    "    dialog.grab_set()\n",
    "\n",
    "    result = [None] # Store the user's selection\n",
    "    params = 120, 120, 20, 10, 3  # button_width, button_height, space_between_buttons_x, space_between_buttons_y, num_columns\n",
    "    total_width = (params[0] * params[4]) + (params[2] * (params[4] - 1))\n",
    "    start_x, start_y = ((bg_image.width() - total_width) / 2), (bg_image.height() / 4)\n",
    "    # Function to handle selection and close dialog\n",
    "    def make_selection(value): result[0] = value; dialog.destroy()\n",
    "    # Create and place buttons based on provided options\n",
    "    for index, (text, value) in enumerate(options.items()):\n",
    "        x, y = start_x + (index % params[4]) * (params[0] + params[2]), start_y + (index // params[4]) * (params[1] + params[3])\n",
    "        tk.Button(dialog, text=text, command=lambda v=value: make_selection(v), font=(\"Helvetica\", 10, \"bold\")).place(x=x, y=y, width=params[0], height=params[1])\n",
    "        \n",
    "    dialog.wait_window() # Wait for the dialog to close before continuing\n",
    "    return result[0]\n",
    "\n",
    "def initialize_capture():\n",
    "    ROOT = tk.Tk()\n",
    "    ROOT.withdraw()  # Hide tkinter root window\n",
    "    # Mapping of analysis and detection functions\n",
    "    ad_map = {1: (squat_front_analysis, squat_front_detection), 2: (squat_side_analysis, squat_side_detection),\n",
    "              3: (squat_back_analysis, squat_back_detection), 4: (knee_raising_analysis, knee_raising_detection),\n",
    "              5: (stand_front_analysis, stand_front_detection), 6: (stand_side_analysis, stand_side_detection)}\n",
    "\n",
    "    a_opts = {\"Front Angle\": 1, \"Side Angle\": 2, \"Balance Back\": 3, \"Balance Test\": 4, \"Balance Front\": 5, \"Balance Side\": 6}\n",
    "    i_opts = {\"Image\": 1, \"Video file\": 2, \"Camera\": 3}\n",
    "    # User selects option or exits if none selected\n",
    "    a_choice = gui(a_opts) or sys.exit(0)  # Exit if no choice\n",
    "    anal_func, detect_func = ad_map[a_choice]\n",
    "    i_choice = gui(i_opts) or sys.exit(0)  # Exit if no choice\n",
    "    # File type filter based on input choice, skips if camera is selected\n",
    "    file_type = [(\"Image files\", \"*.jpg *.jpeg *.png\")] if i_choice == 1 else [(\"Video files\", \"*.mp4 *.mov *.avi\")]\n",
    "    path = filedialog.askopenfilename(title=\"Select the file\", filetypes=file_type) if i_choice != 3 else None\n",
    "    if i_choice != 3 and not path: sys.exit(0)  # Exit if no file selected\n",
    "    # Open video capture: camera for option 3, file path otherwise\n",
    "    cap = cv2.VideoCapture(0 if i_choice == 3 else path)\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS) if cap.isOpened() else 0\n",
    "    return cap, i_choice == 1, path, frame_rate, anal_func, detect_func, a_choice-1\n",
    "\n",
    "def setup_output_writer(cap, is_image, timestamp):\n",
    "    ROOT = tk.Tk()\n",
    "    ROOT.withdraw()  # Hide the root window\n",
    "    output_folder = 'output'\n",
    "    \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    out_path = f\"{output_folder}/Result_{timestamp}\" + ('.jpg' if is_image else '.mp4')\n",
    "    if not is_image:\n",
    "        return cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'MP4V'), cap.get(cv2.CAP_PROP_FPS), (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "    return out_path\n",
    "\n",
    "def process_frame(frame, pose, anal_func, detect_func):\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(image)\n",
    "    if results.pose_landmarks:\n",
    "        # Get the posture and angles data from the analysis function\n",
    "        posture, angles_data = anal_func(results.pose_landmarks.landmark, mp_pose)\n",
    "        # Apply the detection function to annotate the image, also pass angles_data now\n",
    "        annotated_image = detect_func(cv2.cvtColor(image, cv2.COLOR_RGB2BGR), results, posture, angles_data)\n",
    "        return annotated_image, angles_data\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2BGR), {}\n",
    "\n",
    "def get_point(landmarks, landmark):\n",
    "    return landmarks[landmark.value].x, landmarks[landmark.value].y\n",
    "\n",
    "def calculate_angle(a, b, c, reverse=False):\n",
    "    \"\"\"\n",
    "    Calculates the angle formed by three points, with an option to reverse the direction.\n",
    "\n",
    "    Args:\n",
    "    a, b, c (tuple): Coordinates of the points forming the angle (each as an (x, y) tuple).\n",
    "    reverse (bool): If True, calculates the angle in the reverse direction.\n",
    "\n",
    "    Returns:\n",
    "    float: The calculated angle in degrees.\n",
    "    \"\"\"\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    # Calculating the angle depending on the reverse flag\n",
    "    if reverse:\n",
    "        radians = np.arctan2(b[1] - a[1], b[0] - a[0]) - np.arctan2(c[1] - a[1], c[0] - a[0])\n",
    "    else:\n",
    "        radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.degrees(radians)\n",
    "    # Adjusting angle to the range [0, 360] and then normalizing to [-180, 180]\n",
    "    angle = (angle + 360) % 360\n",
    "    if angle > 180:\n",
    "        angle -= 360\n",
    "\n",
    "    return angle\n",
    "\n",
    "def draw_colored_connection(image, results, start_idx, end_idx, color=(255, 0, 0), thickness=2):\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        start, end = landmarks[start_idx], landmarks[end_idx]\n",
    "        cv2.line(image, (int(start.x * image.shape[1]), int(start.y * image.shape[0])), \n",
    "                 (int(end.x * image.shape[1]), int(end.y * image.shape[0])), color, thickness)\n",
    "\n",
    "def calculate_posture_ratio():\n",
    "    total_postures = sum(sum(postures.values()) for section, postures in posture_data.items() if isinstance(postures, dict))\n",
    "    correct_data = posture_data.get(\"Correct\", 0)\n",
    "    correct_count = sum(correct_data.values()) if isinstance(correct_data, dict) else correct_data\n",
    "\n",
    "    section_percentages, top_level_percentages = {}, {}\n",
    "    for section, postures in posture_data.items():\n",
    "        if section != \"Correct\" and isinstance(postures, dict):\n",
    "            section_total = sum(postures.values())\n",
    "            section_percentages[section] = {cond: f\"{(cnt / section_total) * 100:.1f}%\" for cond, cnt in postures.items()}\n",
    "            top_level_percentages[f\"{section} Issue\"] = f\"{(section_total / total_postures) * 100:.1f}%\"\n",
    "\n",
    "    correct_ratio = f\"{(correct_count / max(total_postures, 1)) * 100:.1f}%\"\n",
    "    top_level_percentages[\"Correct Ratio\"] = correct_ratio\n",
    "\n",
    "    return {**section_percentages, **top_level_percentages}\n",
    "\n",
    "\n",
    "def update_posture_data(section, posture_conditions, detected_postures):\n",
    "    if section == \"Correct\":\n",
    "        posture_data[section] = {\"Correct\": posture_data.get(section, {}).get(\"Correct\", 0) + 1}\n",
    "    else:\n",
    "        detected_postures_list = [p.strip() for p in detected_postures.split(\" and \") if p.strip() in posture_conditions]\n",
    "        for posture in detected_postures_list:\n",
    "            posture_data.setdefault(section, {}).setdefault(posture, 0)\n",
    "            posture_data[section][posture] += 1\n",
    "\n",
    "            \n",
    "            \n",
    "def draw_landmarks(image, results, landmark_indices, color=(255, 255, 255), radius=3):\n",
    "\n",
    "    for idx in landmark_indices:\n",
    "        landmark_point = results.pose_landmarks.landmark[idx]\n",
    "        pos = (int(landmark_point.x * image.shape[1]), int(landmark_point.y * image.shape[0]))\n",
    "        cv2.circle(image, pos, radius, color, -1)\n",
    "\n",
    "            \n",
    "            \n",
    "def draw_labeled_box(image, results, joint_landmarks, angles, padding=3, font_scale=0.35, font_thickness=1,\n",
    "                     box_color=(255, 255, 255), text_color=(139, 0, 0), edge_color=(230, 216, 173)): \n",
    "    for joint_index, angle in enumerate(angles):\n",
    "        joint = results.pose_landmarks.landmark[joint_landmarks[joint_index]]\n",
    "        angle_text, pos = f\"{round(angle)}\", (int(joint.x * image.shape[1]) + 10, int(joint.y * image.shape[0]))\n",
    "        text_size = cv2.getTextSize(angle_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)[0]\n",
    "        box_start, box_end = (pos[0] - padding, pos[1] + padding), (pos[0] + text_size[0] + padding, pos[1] - text_size[1] - padding)\n",
    "        cv2.rectangle(image, box_start, box_end, box_color, cv2.FILLED)\n",
    "        cv2.rectangle(image, box_start, box_end, edge_color, 1)\n",
    "        cv2.putText(image, angle_text, (pos[0], pos[1]), cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, font_thickness, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "def generate_report(joint_angles_df, frame_rate, body_labels, analysis_choice, timestamp):\n",
    "    joint_angles_df['Time'] = joint_angles_df.index / frame_rate\n",
    "    joints = joint_angles_df.columns.drop('Time').tolist()\n",
    "\n",
    "    if len(body_labels[analysis_choice]) != len(joints):\n",
    "        # Plot \"No Posture detected.\" message instead of raising error\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        plt.suptitle('Analysis Report', fontsize=20)\n",
    "        plt.text(0.5, 0.5, 'No Posture detected.', fontsize=14, ha='center')\n",
    "        plt.axis('off')\n",
    "        os.makedirs('output', exist_ok=True)\n",
    "        plt.savefig(os.path.join('output', f\"Report_{timestamp}.pdf\"))\n",
    "        plt.close(fig)\n",
    "        return\n",
    "\n",
    "    num_rows, fig_width, fig_height = ((len(joints) + 1) // 2) + 5, 18, (((len(joints) + 1) // 2) + 5) * 4\n",
    "    fig = plt.figure(figsize=(fig_width, fig_height))\n",
    "    fig.suptitle('Analysis Report', fontsize=20, y=1)\n",
    "    gs = GridSpec(num_rows, 4, figure=fig, width_ratios=[3, 1, 3, 1])\n",
    "\n",
    "    for i, joint in enumerate(joints):\n",
    "        row, col = i // 2, (i % 2) * 2\n",
    "        ax_plot = fig.add_subplot(gs[row, col])\n",
    "        ax_plot.plot(joint_angles_df['Time'], joint_angles_df[joint], label=joint)\n",
    "        ax_plot.set_title(body_labels[analysis_choice][i])\n",
    "        ax_plot.set_xlabel('Time (s)')\n",
    "        ax_plot.set_ylabel('Angle (degrees)')\n",
    "        ax_plot.grid(True)\n",
    "\n",
    "        stats = { 'Average': round(np.mean(joint_angles_df[joint]), 2),\n",
    "                  'Max': round(np.max(joint_angles_df[joint]), 2),\n",
    "                  'Min': round(np.min(joint_angles_df[joint]), 2) }\n",
    "        ax_table = fig.add_subplot(gs[row, col + 1])\n",
    "        ax_table.axis('off')\n",
    "        table = ax_table.table(cellText=[[k, f'{v:.2f}'] for k, v in stats.items()], colLabels=['Stat', 'Value'], cellLoc='center', loc='center')\n",
    "        table.auto_set_font_size(True)\n",
    "        table.scale(1, 1.5)\n",
    "\n",
    "    plt.subplots_adjust(hspace=1)\n",
    "    fig.tight_layout()\n",
    "    os.makedirs('output', exist_ok=True)\n",
    "    plt.savefig(os.path.join('output', f\"Report_{timestamp}.pdf\"))\n",
    "    plt.close(fig)\n",
    "    \n",
    "def run_estimation():\n",
    "    global stop_evaluation, joint_angles_df\n",
    "    stop_evaluation, joint_angles_df = False, pd.DataFrame()\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "    cap, is_image, _, frame_rate, anal_func, detect_func, analysis_choice = initialize_capture()\n",
    "    if not cap: return\n",
    "\n",
    "    out = setup_output_writer(cap, is_image, timestamp)\n",
    "\n",
    "    # Start the stop/proceed GUI in a separate thread\n",
    "    gui_thread = threading.Thread(target=show_stop_gui, daemon=True)\n",
    "    gui_thread.start()\n",
    "\n",
    "    with mp.solutions.pose.Pose(min_detection_confidence=0.6 if is_image else 0.9, min_tracking_confidence=0.6 if is_image else 0.9) as pose:\n",
    "        while cap.isOpened() and not stop_evaluation:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "\n",
    "            processed_frame, angles_data = process_frame(frame, pose, anal_func, detect_func)\n",
    "            joint_angles_df = pd.concat([joint_angles_df, pd.DataFrame([angles_data])], ignore_index=True)\n",
    "            cv2.imshow('Mediapipe Feed', processed_frame)\n",
    "            if is_image: cv2.imwrite(out, processed_frame); break\n",
    "            elif out: out.write(processed_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    if out and not is_image: out.release()\n",
    "    gui_thread.join()  # Wait for the user to click 'Proceed' before moving on\n",
    "    posture_percentages = calculate_posture_ratio()\n",
    "    df = pd.DataFrame([{'Section': s, 'Condition': c, 'Percentage': p} for s, cs in posture_percentages.items() for c, p in (cs.items() if isinstance(cs, dict) else [(None, cs)])])\n",
    "    generate_report(joint_angles_df, frame_rate, body_labels, analysis_choice, timestamp)\n",
    "    return df\n",
    "\n",
    "\n",
    "def show_stop_gui():\n",
    "    global stop_evaluation\n",
    "    \n",
    "    def on_button_click():\n",
    "        if button['text'] == 'Stop':\n",
    "            global stop_evaluation\n",
    "            stop_evaluation = True  # Signal to stop the current analysis\n",
    "            button.config(text='Proceed')  # Change button text to 'Proceed' after stopping\n",
    "        else:\n",
    "            root.destroy()  # Close the GUI and proceed to next round\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Analysis Control\")\n",
    "    tk.Label(root, text=\"Click 'Stop' to stop analysis \\nClick 'Proceed' to complete analysis.\").pack(pady=20)\n",
    "    \n",
    "    button = tk.Button(root, text=\"Stop\", command=on_button_click)\n",
    "    button.pack(pady=10)\n",
    "    \n",
    "    root.protocol(\"WM_DELETE_WINDOW\", root.destroy)  # Ensure the window can be closed directly\n",
    "    root.mainloop()\n",
    "\n",
    "    return stop_evaluation\n",
    "\n",
    "def main():\n",
    "    while run:\n",
    "        run_estimation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8f6f4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.1 Squat Front"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707b7fd9",
   "metadata": {},
   "source": [
    "### 1.1.1 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fb2da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squat_front_analysis(landmarks, mp_pose):\n",
    "    \"\"\"\n",
    "    Analyzes front-view squat posture based on landmarks.\n",
    "\n",
    "    Args:\n",
    "    - landmarks (list): List of detected pose landmarks.\n",
    "    - mp_pose (module): Mediapipe pose module for landmark references.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Returns a tuple containing the detected posture and a tuple of angles (left knee angle, right knee angle, hip angle difference).\n",
    "    \"\"\"\n",
    "\n",
    "    # Get points\n",
    "    left_shoulder, left_elbow, left_wrist, left_index, left_hip, left_knee, left_ankle, left_foot_index = map(lambda lm: get_point(landmarks, lm), \n",
    "                                                                                                  [landmarks_to_draw[11], landmarks_to_draw[13], landmarks_to_draw[15], \n",
    "                                                                                                  landmarks_to_draw[23], landmarks_to_draw[25], landmarks_to_draw[27],\n",
    "                                                                                                  landmarks_to_draw[31], landmarks_to_draw[19]])\n",
    "    right_shoulder, right_elbow, right_wrist, right_index, right_hip, right_knee, right_ankle, right_foot_index = map(lambda lm: get_point(landmarks, lm), \n",
    "                                                                                                  [landmarks_to_draw[12], landmarks_to_draw[14], landmarks_to_draw[16], \n",
    "                                                                                                  landmarks_to_draw[24], landmarks_to_draw[26], landmarks_to_draw[28],\n",
    "                                                                                                  landmarks_to_draw[32], landmarks_to_draw[20]])\n",
    "    \n",
    "    \n",
    "    # Calculate shoulder angles\n",
    "    left_shoulder_angle = abs(calculate_angle(left_hip, left_shoulder, left_elbow))\n",
    "    right_shoulder_angle = abs(calculate_angle(right_hip, right_shoulder, right_elbow))\n",
    "    \n",
    "    # Calculate elbow angles\n",
    "    left_elbow_angle = abs(calculate_angle(left_shoulder, left_elbow, left_wrist))\n",
    "    right_elbow_angle = abs(calculate_angle(right_shoulder, right_elbow, right_wrist))\n",
    "    \n",
    "    # Calculate wrist angles\n",
    "    left_wrist_angle = abs(calculate_angle(left_elbow, left_wrist, left_index, True))\n",
    "    right_wrist_angle = abs(calculate_angle(right_elbow, right_wrist, right_index, True))\n",
    "    \n",
    "    # Calculate hip angles\n",
    "    left_hip_angle = abs(calculate_angle(left_shoulder, left_hip, left_knee))\n",
    "    right_hip_angle = abs(calculate_angle(right_shoulder, right_hip, right_knee))\n",
    "    \n",
    "    # Calculate knee angles\n",
    "    left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "    right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "    \n",
    "    # Calculate ankle angles\n",
    "    left_ankle_angle = abs(calculate_angle(left_ankle, left_foot_index, left_knee, True))\n",
    "    right_ankle_angle = abs(calculate_angle(right_ankle, right_foot_index, right_knee, True))\n",
    "    \n",
    "    # Calcuate hip angles\n",
    "    left_hip1_angle = abs(calculate_angle(right_hip, left_hip, [left_hip[0], 0]))\n",
    "    right_hip1_angle = abs(calculate_angle(left_hip, right_hip, [right_hip[0], 0]))\n",
    "    \n",
    "    # Determine if hips are level\n",
    "    left_hip_level = (left_hip_angle - right_hip_angle) > sml_buffer\n",
    "    right_hip_level = (right_hip_angle - left_hip_angle) > sml_buffer\n",
    "    \n",
    "    \n",
    "    # Calculate the midpoint of the shoulders\n",
    "    shoulder_mid_x = (left_shoulder[0] + right_shoulder[0]) / 2\n",
    "    # Calculate the central vertical line (midpoint between hips)\n",
    "    central_vertical_line_x = (left_hip[0] + right_hip[0]) / 2\n",
    "    \n",
    "    \n",
    "    correct_degree = 110\n",
    "    \n",
    "    # Outward position logic\n",
    "    left_knee_outward = (left_knee_angle + correct_degree) > buffer\n",
    "    right_knee_outward = (right_knee_angle - correct_degree) < -buffer\n",
    "\n",
    "    # Inward position logic\n",
    "    left_knee_inward = (left_knee_angle + correct_degree) < -buffer\n",
    "    right_knee_inward = (right_knee_angle - correct_degree) > buffer\n",
    "\n",
    "    \n",
    "    # update posture condition\n",
    "    knee_postures = [\"Knees outwards\", \"Knees inwards\"]\n",
    "    hip_postures = [\"H.L. hip\", \"H.R. hip\"]\n",
    "\n",
    "    posture = \"\"\n",
    "    if (left_knee_outward or right_knee_outward) and (abs(left_knee_angle) < correct_degree + buffer and abs(right_knee_angle) < correct_degree + buffer):\n",
    "        posture += sign + knee_postures[0]\n",
    "    elif (left_knee_inward or right_knee_inward) and (abs(left_knee_angle) < correct_degree + buffer and abs(right_knee_angle) < correct_degree + buffer):\n",
    "        posture += sign + knee_postures[1]\n",
    "    if left_hip_level:\n",
    "        posture += sign + hip_postures[0]\n",
    "    elif right_hip_level:\n",
    "        posture += sign + hip_postures[1]\n",
    "    if posture == \"\":\n",
    "        posture += \"| Correct\"\n",
    "\n",
    "    detected_postures = posture.split(sign)\n",
    "    for detected_posture in detected_postures:\n",
    "        detected_posture = detected_posture.strip()\n",
    "        if detected_posture in knee_postures:\n",
    "            update_posture_data(\"Knee\", knee_postures, detected_posture)\n",
    "        elif detected_posture in hip_postures:\n",
    "            update_posture_data(\"Hip\", hip_postures, detected_posture)\n",
    "        elif detected_posture == \"Correct\":\n",
    "            posture_data[\"Correct\"] = posture_data.get(\"Correct\", 0) + 1\n",
    "\n",
    "    # Return posture and angles as a tuple\n",
    "    return posture, (left_shoulder_angle, right_shoulder_angle, left_elbow_angle, right_elbow_angle, left_wrist_angle, \n",
    "                     right_wrist_angle, left_hip_angle, right_hip_angle, abs(left_knee_angle),  abs(right_knee_angle), \n",
    "                     left_ankle_angle, right_ankle_angle, shoulder_mid_x, central_vertical_line_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5431f3",
   "metadata": {},
   "source": [
    "### 1.1.2 Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd7147ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squat_front_detection(image, results, knee_position, angles):\n",
    "    \"\"\"\n",
    "    Analyzes and annotates a front-view image of a squatting posture.\n",
    "\n",
    "    Args:\n",
    "    - image (numpy.ndarray): The image on which to perform the analysis and annotations.\n",
    "    - results (object): The detected pose landmarks from a pose estimation model.\n",
    "    - knee_position (str): Description of the knee position (e.g., \"Correct\", \"Too forward\").\n",
    "    - angles (tuple): A tuple containing the angles (left knee angle, right knee angle, hip angle difference).\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The annotated image with landmarks, angles, and posture information.\n",
    "    \"\"\"\n",
    "    # Unpack angles to get the knee angles and hip angle difference\n",
    "    if results.pose_landmarks:\n",
    "\n",
    "        \n",
    "        \n",
    "        # Draw the lines\n",
    "        connect_idx = [(23, 25), (25, 31), (27, 31), (24, 26), (26, 32), (28, 32), (11, 13), (13, 15),\n",
    "                        (12, 14), (14, 16), (11, 23), (12, 24), (11, 12), (23, 24)]\n",
    "        colors = [(255, 0, 0)] * 12 + [(0, 0, 255)] * 4\n",
    "        for (p1, p2), color in zip(connect_idx, colors):\n",
    "            draw_colored_connection(image, results, landmarks_to_draw[p1], landmarks_to_draw[p2], color=color)\n",
    "        \n",
    "        # Draw the specified landmarks\n",
    "        landmark_idx = [11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 31, 32, 27, 28]\n",
    "        draw_landmarks(image, results, landmark_idx) \n",
    "        joint_landmarks = [landmarks_to_draw[idx].value for idx in landmark_idx] # Draw the lines and display angles\n",
    "        draw_labeled_box(image, results, joint_landmarks, angles[:-2]) # Call the draw_labeled_box function\n",
    "        \n",
    "        # central line\n",
    "        central_vertical_line_x, shoulder_mid_x = angles[-1], angles[-2]\n",
    "        # Draw central vertical line\n",
    "        central_vertical_line_pixel_x = int(central_vertical_line_x * image.shape[1])\n",
    "        cv2.line(image, (central_vertical_line_pixel_x, 0), (central_vertical_line_pixel_x, image.shape[0]), (255, 255, 0), 1)\n",
    "\n",
    "        # Calculate middle dot position (midpoint between shoulders)\n",
    "        middle_dot_x = int(shoulder_mid_x * image.shape[1])\n",
    "        middle_dot_y = int((results.pose_landmarks.landmark[landmarks_to_draw[landmark_idx[0]]].y +\n",
    "                            results.pose_landmarks.landmark[landmarks_to_draw[landmark_idx[1]]].y) / 2 * image.shape[0])\n",
    "        \n",
    "        # Draw the middle dot\n",
    "        cv2.circle(image, (middle_dot_x, middle_dot_y), 3, (0, 255, 0), -1)  # Green dot\n",
    "        shoulder_midpoint_pos = (middle_dot_x, middle_dot_y)\n",
    "        # For \"Shoulder Diff\" text\n",
    "        deviation_text = 'Left' if (shoulder_mid_x - central_vertical_line_x) > 0 else 'Right' if (shoulder_mid_x - central_vertical_line_x) < 0 else 'Centered'\n",
    "        deviation_full_text = f'Dev: {deviation_text}'\n",
    "\n",
    "        # Calculate size of the text for background box calculation\n",
    "        deviation_text_size = cv2.getTextSize(deviation_full_text, cv2.FONT_HERSHEY_COMPLEX , 0.4, 2)[0]\n",
    "        deviation_box_start = (central_vertical_line_pixel_x + 5, shoulder_midpoint_pos[1] + 15 - deviation_text_size[1] - 2)\n",
    "        deviation_box_end = (deviation_box_start[0] + deviation_text_size[0] + 4, shoulder_midpoint_pos[1] + 15 + 2)\n",
    "        cv2.rectangle(image, deviation_box_start, deviation_box_end, (255, 255, 255), cv2.FILLED)\n",
    "        cv2.rectangle(image, deviation_box_start, deviation_box_end, (230, 216, 173), 1)\n",
    "        # put the text on top of the boxes\n",
    "        cv2.putText(image, deviation_full_text, (deviation_box_start[0], deviation_box_start[1] + deviation_text_size[1] + 2), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (139, 0, 0), 1)\n",
    "        \n",
    "\n",
    "        # Add text for knee position if necessary\n",
    "        cv2.putText(image, f'Posture: {knee_position}', (10, 30), cv2.FONT_HERSHEY_COMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0df6385",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.2 Squat Side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26487618",
   "metadata": {},
   "source": [
    "### 1.2.1 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f8dbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squat_side_analysis(landmarks, mp_pose):\n",
    "    \"\"\"\n",
    "    Analyzes front-view squat posture based on landmarks.\n",
    "\n",
    "    Args:\n",
    "    - landmarks (list): List of detected pose landmarks.\n",
    "    - mp_pose (module): Mediapipe pose module for landmark references.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Returns a tuple containing the detected posture and a tuple of angles (left knee angle, right knee angle, hip angle difference).\n",
    "    \"\"\"\n",
    "    # Get points\n",
    "    left_shoulder, left_elbow, left_wrist, left_hip, left_knee, left_ankle, left_foot_index, left_ear = map(lambda lm: get_point(landmarks, lm), \n",
    "                                                                                                  [landmarks_to_draw[11], landmarks_to_draw[13], landmarks_to_draw[15], \n",
    "                                                                                                  landmarks_to_draw[23], landmarks_to_draw[25], landmarks_to_draw[27],\n",
    "                                                                                                  landmarks_to_draw[31], landmarks_to_draw[7]])\n",
    "    right_shoulder, right_elbow, right_wrist, right_hip, right_knee, right_ankle, right_foot_index, right_ear = map(lambda lm: get_point(landmarks, lm), \n",
    "                                                                                                  [landmarks_to_draw[12], landmarks_to_draw[14], landmarks_to_draw[16], \n",
    "                                                                                                  landmarks_to_draw[24], landmarks_to_draw[26], landmarks_to_draw[28],\n",
    "                                                                                                  landmarks_to_draw[32], landmarks_to_draw[8]])\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    # Analyse hip posture\n",
    "    # Calculate hip angles\n",
    "    left_hip_angle = abs(calculate_angle(left_shoulder, left_hip, [left_hip[0], 0]))\n",
    "    right_hip_angle = abs(calculate_angle(right_shoulder, right_hip, [right_hip[0], 0]))\n",
    "    \n",
    "    # Calculate elbow angles\n",
    "    left_elbow_angle = abs(calculate_angle(left_shoulder, left_elbow, left_wrist))\n",
    "    right_elbow_angle = abs(calculate_angle(right_shoulder, right_elbow, right_wrist))\n",
    "    \n",
    "    # Calculate shoulder angles\n",
    "    left_shoulder_angle = abs(calculate_angle(left_elbow, left_shoulder, left_hip))\n",
    "    right_shoulder_angle = abs(calculate_angle(right_elbow, right_shoulder, right_hip))\n",
    "    \n",
    "    # Calculate torso angles\n",
    "    left_torso_angle = abs(calculate_angle(left_shoulder, left_hip, left_knee))\n",
    "    right_torso_angle = abs(calculate_angle(right_shoulder, left_hip, right_knee))\n",
    "    \n",
    "    # Calculate ankle front angles\n",
    "    left_ankle_f_angle = abs(calculate_angle(left_knee, left_ankle, left_foot_index))\n",
    "    right_ankle_f_angle = abs(calculate_angle(right_knee, right_ankle, right_foot_index))\n",
    "    \n",
    "    \n",
    "     # Calculate neck angle\n",
    "    left_neck_angle = abs(calculate_angle([left_shoulder[0], 0], left_shoulder, left_ear))\n",
    "    right_neck_angle = abs(calculate_angle([right_shoulder[0], 0], right_shoulder, right_ear))\n",
    "\n",
    "    # Determine if shoulder angle is correct\n",
    "    correct_neck_angle = 0  # Correct shoulder angle (ideal posture)\n",
    "    neck_forward = (left_neck_angle > (correct_neck_angle + buffer)) or (right_neck_angle > (correct_neck_angle + buffer))\n",
    "    \n",
    "    # Analyse ankle posture\n",
    "    # Calculate ankle angles\n",
    "    left_ankle_angle = abs(calculate_angle(left_knee, left_ankle, [left_ankle[0], 0]))\n",
    "    right_ankle_angle = abs(calculate_angle(right_knee, right_ankle, [right_ankle[0], 0]))\n",
    "    \n",
    "    # Determine if hip-shoulder and ankle-knee lines are asymmetric\n",
    "    left_asymmetric = abs(left_hip_angle - left_ankle_angle) > buffer + 15\n",
    "    right_asymmetric = abs(right_hip_angle - right_ankle_angle) > buffer + 15\n",
    "    \n",
    "    \n",
    "    # Analyse knee posture\n",
    "    # Calculate knee angles, subtract 180 for reflection\n",
    "    left_knee_angle = abs(calculate_angle(left_hip, left_knee, left_ankle))\n",
    "    right_knee_angle = abs(calculate_angle(right_hip, right_knee, right_ankle))\n",
    "    \n",
    "    # Determine if knee angles are correct\n",
    "    correct_knee_angle = 38\n",
    "    knee_low = any([abs(left_knee_angle) > (correct_knee_angle - buffer), abs(right_knee_angle) > (correct_knee_angle - buffer)])\n",
    "\n",
    "    # update posture condition\n",
    "    asym_postures = [\"L. body asym\", \"R. body asym\"]\n",
    "    knee_postures = [\"Low knees\"]\n",
    "    neck_postures = [\"Neck forward\"]\n",
    "    \n",
    "    posture = \"\"\n",
    "    if left_asymmetric:\n",
    "        posture += sign + asym_postures[0]\n",
    "    if right_asymmetric:\n",
    "        posture += sign + asym_postures[1]\n",
    "    if knee_low and (abs(left_knee_angle) < correct_knee_angle and abs(right_knee_angle) < correct_knee_angle):\n",
    "        posture += sign + knee_postures[0]\n",
    "    if neck_forward:\n",
    "        posture += sign + neck_postures[0]\n",
    "    if posture == \"\":\n",
    "        posture = \"Correct\"\n",
    "        \n",
    "    detected_postures = posture.split(sign)\n",
    "    for detected_posture in detected_postures:\n",
    "        detected_posture = detected_posture.strip()\n",
    "        if detected_posture in asym_postures:\n",
    "            update_posture_data(\"Symmetry\", asym_postures, detected_posture)\n",
    "        elif detected_posture in knee_postures:\n",
    "            update_posture_data(\"Knee\", knee_postures, detected_posture)\n",
    "        elif detected_posture in neck_postures:\n",
    "            update_posture_data(\"Neck\", neck_postures, detected_posture)\n",
    "        elif detected_posture == \"Correct\":\n",
    "            posture_data[\"Correct\"] = posture_data.get(\"Correct\", 0) + 1\n",
    "\n",
    "        \n",
    "    return posture, (left_shoulder_angle, right_shoulder_angle, left_elbow_angle, right_elbow_angle, \n",
    "                     left_hip_angle, right_hip_angle, left_knee_angle, right_knee_angle, left_ankle_angle, \n",
    "                     right_ankle_angle, left_neck_angle, right_neck_angle, left_torso_angle, right_torso_angle,\n",
    "                     left_ankle_f_angle, right_ankle_f_angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bcf3c7",
   "metadata": {},
   "source": [
    "### 1.2.2 Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58a1df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squat_side_detection(image, results, posture, angles):\n",
    "    \"\"\"\n",
    "    Analyzes and annotates a side-view image of a squatting posture.\n",
    "\n",
    "    Args:\n",
    "    - image (numpy.ndarray): The image on which to perform the analysis and annotations.\n",
    "    - results (object): The detected pose landmarks from a pose estimation model.\n",
    "    - posture (str): Description of the overall posture.\n",
    "    - angles (list): A list of knee angles.\n",
    "    - body_tilts (list): List of body tilts (left and right hip and ankle angles).\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The annotated image with landmarks and angles.\n",
    "    \"\"\"\n",
    "    if results.pose_landmarks:\n",
    "        \n",
    "        \n",
    "        # Draw the lines with specified colors\n",
    "        connect_idx = [(7, 11), (8, 12), (11, 23), (25, 27), (12, 24), (26, 28), (11, 13), (13, 15), \n",
    "               (12, 14), (14, 16), (23, 25), (27, 31), (24, 26), (28, 32)]\n",
    "    \n",
    "        for i, (p1, p2) in enumerate(connect_idx):\n",
    "            color = (0,165,255) if i < 2 else ((0, 0, 255) if i < 6 else (255, 0, 0))\n",
    "            draw_colored_connection(image, results, landmarks_to_draw[p1], landmarks_to_draw[p2], color=color)\n",
    "        \n",
    "        # Draw the specified landmarks\n",
    "        landmark_idx = [11, 12, 13, 14, 23, 24, 25, 26, 27, 28, 7, 8, 15, 16, 31, 32]\n",
    "        draw_landmarks(image, results, landmark_idx) \n",
    "        joint_landmarks = [landmarks_to_draw[idx].value for idx in landmark_idx]\n",
    "        draw_labeled_box(image, results, joint_landmarks, angles[:-4]) # Call the draw_labeled_box function\n",
    "        \n",
    "\n",
    "        \n",
    "        # Find pose direction\n",
    "        left_foot_index_x, right_foot_index_x = results.pose_landmarks.landmark[31].x, results.pose_landmarks.landmark[32].x\n",
    "        left_ankle_x, right_ankle_x = results.pose_landmarks.landmark[27].x, results.pose_landmarks.landmark[28].x\n",
    "        if left_foot_index_x < left_ankle_x or right_foot_index_x < right_ankle_x:\n",
    "            direction = 1\n",
    "        else:\n",
    "            direction = -1\n",
    "\n",
    "            \n",
    "            \n",
    "        # Draw box and text for torsos and angles\n",
    "        landmark_idx_extra = [23, 24, 27, 28]\n",
    "        joint_names_extra = ['L Torso', 'R Torso', 'L Ankle', 'R Ankle']\n",
    "        joint_landmarks_extra = [landmarks_to_draw[idx].value for idx in landmark_idx_extra]\n",
    "        for joint_index, angle in enumerate(angles[-4:]):\n",
    "            joint_landmark = results.pose_landmarks.landmark[joint_landmarks_extra[joint_index]]\n",
    "\n",
    "            angle_text = f\"{round(angle)}\"\n",
    "            text_x = int(joint_landmark.x * image.shape[1]) - (90 * direction)\n",
    "            text_y = int(joint_landmark.y * image.shape[0])\n",
    "\n",
    "            # Determine the size of the text box\n",
    "            text_size, _ = cv2.getTextSize(angle_text, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)\n",
    "            text_width, text_height = text_size\n",
    "\n",
    "            box_start = (text_x - 2, text_y + 2)\n",
    "            box_end = (text_x + text_width + 2, text_y - text_height - 2)\n",
    "\n",
    "            # Draw the filled rectangle (background)\n",
    "            cv2.rectangle(image, box_start, box_end, (255, 255, 255), cv2.FILLED)\n",
    "            # Draw the border rectangle (edges)\n",
    "            cv2.rectangle(image, box_start, box_end, (230, 216, 173), 1)\n",
    "\n",
    "            # Now put the text (in specified text color)\n",
    "            text_org = (text_x, text_y)\n",
    "            cv2.putText(image, angle_text, text_org, cv2.FONT_HERSHEY_SIMPLEX, 0.35, (139, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "        # Add text for knee position if necessary\n",
    "        cv2.putText(image, f'Posture: {posture}', (0, 20), cv2.FONT_HERSHEY_COMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f7602b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.3 Squat Back "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065b7108",
   "metadata": {},
   "source": [
    "### 1.3.1 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eacb512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squat_back_analysis(landmarks, mp_pose):\n",
    "    \"\"\"\n",
    "    Analyzes back-view squat posture based on landmarks.\n",
    "\n",
    "    Args:\n",
    "    - landmarks (list): List of detected pose landmarks.\n",
    "    - mp_pose (module): Mediapipe pose module for landmark references.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Returns a tuple containing the detected posture and a tuple of angles (shoulder angle difference, hip angle difference).\n",
    "    \"\"\"\n",
    "\n",
    "    # Get points\n",
    "    left_shoulder, left_hip, left_elbow = map(lambda lm: get_point(landmarks, lm), [pose_landmark.LEFT_SHOULDER, pose_landmark.LEFT_HIP, pose_landmark.LEFT_ELBOW])\n",
    "    right_shoulder, right_hip, right_elbow = map(lambda lm: get_point(landmarks, lm), [pose_landmark.RIGHT_SHOULDER, pose_landmark.RIGHT_HIP, pose_landmark.RIGHT_ELBOW])\n",
    "    \n",
    "    # Posture Analysis\n",
    "    # Calculate shoulder angles\n",
    "    left_shoulder_angle = abs(calculate_angle(right_shoulder, left_shoulder, [left_shoulder[0], 0]))\n",
    "    right_shoulder_angle = abs(calculate_angle(left_shoulder, right_shoulder, [right_shoulder[0], 0]))\n",
    "    \n",
    "    # Determine if shoulders are level\n",
    "    left_shoulder_high = left_shoulder_angle - right_shoulder_angle > sml_buffer\n",
    "    right_shoulder_high = right_shoulder_angle - left_shoulder_angle > sml_buffer\n",
    "\n",
    "     # Calculate hip angles\n",
    "    left_hip_angle = abs(calculate_angle(right_hip, left_hip, [left_hip[0], 0]))\n",
    "    right_hip_angle = abs(calculate_angle(left_hip, right_hip, [right_hip[0], 0]))\n",
    "    \n",
    "    # Determine if hips are level\n",
    "    left_hip_high = left_hip_angle - right_hip_angle > sml_buffer\n",
    "    right_hip_high = right_hip_angle - left_hip_angle > sml_buffer\n",
    "    \n",
    "    # Calculate elbow angles\n",
    "    left_elbow_angle = abs(calculate_angle(right_elbow, left_elbow, [left_elbow[0], 0]))\n",
    "    right_elbow_angle = abs(calculate_angle(left_elbow, right_elbow, [right_elbow[0], 0]))\n",
    "    \n",
    "    # Determine if elbows are level\n",
    "    left_elbow_high = left_elbow_angle - right_elbow_angle > sml_buffer\n",
    "    right_elbow_high = right_elbow_angle - left_elbow_angle > sml_buffer\n",
    "    \n",
    "\n",
    "    # Update posture condition\n",
    "    shoulder_postures = [\"H.L. shoulder\", \"H.R. shoulder\"]\n",
    "    hip_postures = [\"H.L. hip\", \"H.R. hip\"]\n",
    "    posture = \"\"\n",
    "    if left_shoulder_high:\n",
    "        posture += sign + shoulder_postures[0]\n",
    "    elif right_shoulder_high:\n",
    "        posture += sign + shoulder_postures[1]\n",
    "    if left_hip_high:\n",
    "        posture += sign + hip_postures[0]\n",
    "    elif right_hip_high:\n",
    "        posture += sign + hip_postures[1]\n",
    "    if posture == \"\":\n",
    "        posture = \"Correct\"\n",
    "\n",
    "    detected_postures = posture.split(sign)\n",
    "    for detected_posture in detected_postures:\n",
    "        detected_posture = detected_posture.strip()\n",
    "        if detected_posture in shoulder_postures:\n",
    "            update_posture_data(\"Shoulder\", shoulder_postures, detected_posture)\n",
    "        elif detected_posture in hip_postures:\n",
    "            update_posture_data(\"Hip\", hip_postures, detected_posture)\n",
    "        elif detected_posture == \"Correct\":\n",
    "            posture_data[\"Correct\"] = posture_data.get(\"Correct\", 0) + 1     \n",
    "        \n",
    "        \n",
    "    return posture, (left_shoulder_angle - right_shoulder_angle, left_elbow_angle - right_elbow_angle, left_hip_angle - right_hip_angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41587520",
   "metadata": {},
   "source": [
    "### 1.3.2 Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05630747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squat_back_detection(image, results, posture, angles):\n",
    "    if results.pose_landmarks:\n",
    "        landmark_idx = [11, 12, 13, 14, 23, 24]\n",
    "        # Draw the lines\n",
    "        draw_colored_connection(image, results, landmarks_to_draw[landmark_idx[0]], landmarks_to_draw[landmark_idx[1]])\n",
    "        draw_colored_connection(image, results, landmarks_to_draw[landmark_idx[2]], landmarks_to_draw[landmark_idx[3]])\n",
    "        draw_colored_connection(image, results, landmarks_to_draw[landmark_idx[4]], landmarks_to_draw[landmark_idx[5]])\n",
    "        draw_colored_connection(image, results, landmarks_to_draw[landmark_idx[0]], landmarks_to_draw[landmark_idx[4]], color=(0, 0, 255))\n",
    "        draw_colored_connection(image, results, landmarks_to_draw[landmark_idx[1]], landmarks_to_draw[landmark_idx[5]], color=(0, 0, 255))\n",
    "\n",
    "        \n",
    "        draw_landmarks(image, results, landmark_idx) # Draw the specified landmarks\n",
    "\n",
    "        joint_landmarks = [landmarks_to_draw[idx].value for idx in landmark_idx[::2]] # Draw the lines and display angles\n",
    "        draw_labeled_box(image, results, joint_landmarks, angles) # Call the draw_labeled_box function\n",
    "\n",
    "        # Add text for posture\n",
    "        cv2.putText(image, f'Posture: {posture}', (20, 50), cv2.FONT_HERSHEY_COMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7338b0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Knee Raising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19529e1a",
   "metadata": {},
   "source": [
    "### 2.0.1 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3967ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knee_raising_analysis(landmarks, mp_pose):\n",
    "    \"\"\"\n",
    "    Analyzes posture during knee-raising exercises based on landmarks.\n",
    "\n",
    "    Args:\n",
    "    - landmarks (list): List of detected pose landmarks.\n",
    "    - mp_pose (module): Mediapipe pose module for landmark references.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Returns a tuple containing the detected posture and a list with shoulder angle difference, shoulder midpoint x-coordinate, and central vertical line x-coordinate.\n",
    "    \"\"\"\n",
    "    # Get points for shoulders and hips\n",
    "    left_shoulder, left_hip = map(lambda lm: get_point(landmarks, lm), [pose_landmark.LEFT_SHOULDER, pose_landmark.LEFT_HIP])\n",
    "    right_shoulder, right_hip = map(lambda lm: get_point(landmarks, lm), [pose_landmark.RIGHT_SHOULDER, pose_landmark.RIGHT_HIP])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Posture Analysis\n",
    "    # Calculate shoulder angles\n",
    "    left_shoulder_angle = abs(calculate_angle(right_shoulder, left_shoulder, [left_shoulder[0], 0]))\n",
    "    right_shoulder_angle = abs(calculate_angle(left_shoulder, right_shoulder, [right_shoulder[0], 0]))\n",
    "    \n",
    "    # Determine if shoulders are level\n",
    "    left_shoulder_high = left_shoulder_angle - right_shoulder_angle > sml_buffer\n",
    "    right_shoulder_high = right_shoulder_angle - left_shoulder_angle > sml_buffer\n",
    "\n",
    "    \n",
    "    \n",
    "    # Calculate the midpoint of the shoulders\n",
    "    shoulder_mid_x = (left_shoulder[0] + right_shoulder[0]) / 2\n",
    "    # Calculate the central vertical line (midpoint between hips)\n",
    "    central_vertical_line_x = (left_hip[0] + right_hip[0]) / 2\n",
    "    \n",
    "    mp_buffer = 0.025 # set buffer for midpoint\n",
    "    # Determine if the shoulder mid point is over the left or right of the hip mid point\n",
    "    mid_point_left = (shoulder_mid_x - central_vertical_line_x) < -mp_buffer\n",
    "    mid_point_right = (shoulder_mid_x - central_vertical_line_x) > mp_buffer\n",
    "    # Update posture condition\n",
    "    shoulder_postures = [\"H.L. shoulder\", \"H.R. shoulder\"]\n",
    "    mp_postures = [\"Body too left\", \"Body too right\"]\n",
    "    \n",
    "    posture = \"\"\n",
    "    if left_shoulder_high:\n",
    "        posture += sign + shoulder_postures[0]\n",
    "    elif right_shoulder_high:\n",
    "        posture += sign + shoulder_postures[1]\n",
    "    if mid_point_left:\n",
    "        posture += sign + mp_postures[0]\n",
    "    elif mid_point_right:\n",
    "        posture += sign + mp_postures[1]\n",
    "    if posture == \"\":\n",
    "        posture = \"Correct\"\n",
    "\n",
    "    detected_postures = posture.split(sign)\n",
    "    for detected_posture in detected_postures:\n",
    "        detected_posture = detected_posture.strip()\n",
    "        if detected_posture in shoulder_postures:\n",
    "            update_posture_data(\"Shoulder\", shoulder_postures, detected_posture)\n",
    "        elif detected_posture in mp_postures:\n",
    "            update_posture_data(\"Mid Point\", mp_postures, detected_posture)\n",
    "        elif detected_posture == \"Correct\":\n",
    "            posture_data[\"Correct\"] = posture_data.get(\"Correct\", 0) + 1 \n",
    "\n",
    "    return posture, (left_shoulder_angle - right_shoulder_angle, shoulder_mid_x, central_vertical_line_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bf3764",
   "metadata": {},
   "source": [
    "### 2.0.2 Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fda23ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knee_raising_detection(image, results, posture, angles):\n",
    "    \"\"\"\n",
    "    Analyzes and annotates an image for knee raising exercises.\n",
    "\n",
    "    Args:\n",
    "    - image (numpy.ndarray): The image on which to perform the analysis and annotations.\n",
    "    - results (object): The detected pose landmarks from a pose estimation model.\n",
    "    - posture (str): Description of the overall posture.\n",
    "    - angles (tuple): Contains analysis data like shoulder vertical difference,\n",
    "                                shoulder midpoint, and central vertical line position.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The annotated image with landmarks, vertical line, and deviation information.\n",
    "    \"\"\"\n",
    "\n",
    "    shoulder_vertical_difference, shoulder_mid_x, central_vertical_line_x = angles\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        landmark_idx = [11, 12, 23, 24]\n",
    "        # Draw the lines\n",
    "        draw_colored_connection(image, results, landmarks_to_draw[landmark_idx[0]], landmarks_to_draw[landmark_idx[1]])\n",
    "        draw_colored_connection(image, results, landmarks_to_draw[landmark_idx[2]], landmarks_to_draw[landmark_idx[3]], color=(0, 0, 255))\n",
    "        draw_colored_connection(image, results, landmarks_to_draw[landmark_idx[0]], landmarks_to_draw[landmark_idx[2]], color=(0, 0, 255))\n",
    "        draw_colored_connection(image, results, landmarks_to_draw[landmark_idx[1]], landmarks_to_draw[landmark_idx[3]], color=(0, 0, 255))\n",
    "\n",
    "        \n",
    "        # Draw central vertical line\n",
    "        central_vertical_line_x, shoulder_mid_x = angles[-1], angles[-2]\n",
    "        # Draw central vertical line\n",
    "        central_vertical_line_pixel_x = int(central_vertical_line_x * image.shape[1])\n",
    "        cv2.line(image, (central_vertical_line_pixel_x, 0), (central_vertical_line_pixel_x, image.shape[0]), (255, 255, 0), 1)\n",
    "        # Calculate middle dot position (midpoint between shoulders)\n",
    "        middle_dot_x = int(shoulder_mid_x * image.shape[1])\n",
    "        middle_dot_y = int((results.pose_landmarks.landmark[landmarks_to_draw[landmark_idx[0]]].y +\n",
    "                            results.pose_landmarks.landmark[landmarks_to_draw[landmark_idx[1]]].y) / 2 * image.shape[0])\n",
    "        draw_landmarks(image, results, landmark_idx)\n",
    "        # Draw the middle dot\n",
    "        cv2.circle(image, (middle_dot_x, middle_dot_y), 3, (0, 255, 0), -1)  # Green dot\n",
    "        \n",
    "        # Calculate positions for drawing text\n",
    "        shoulder_midpoint_pos = (middle_dot_x, middle_dot_y)\n",
    "    \n",
    "        # For \"Shoulder Diff\" text\n",
    "        shoulder_diff_text = f'Diff: {round(abs(shoulder_vertical_difference), 1)}'\n",
    "        deviation_text = 'Left' if (shoulder_mid_x - central_vertical_line_x) > 0 else 'Right' if (shoulder_mid_x - central_vertical_line_x) < 0 else 'Centered'\n",
    "        deviation_full_text = f'Dev: {deviation_text}'\n",
    "\n",
    "        # Calculate size of the text for background box calculation\n",
    "        shoulder_diff_text_size = cv2.getTextSize(shoulder_diff_text, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)[0]\n",
    "        deviation_text_size = cv2.getTextSize(deviation_full_text, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)[0]\n",
    "\n",
    "        # Shoulder Diff Box\n",
    "        shoulder_diff_box_start = (shoulder_midpoint_pos[0] + 5, shoulder_midpoint_pos[1] - 5 - shoulder_diff_text_size[1] - 2)\n",
    "        shoulder_diff_box_end = (shoulder_diff_box_start[0] + shoulder_diff_text_size[0] + 4, shoulder_midpoint_pos[1] - 5 + 2)\n",
    "        cv2.rectangle(image, shoulder_diff_box_start, shoulder_diff_box_end, (255, 255, 255), cv2.FILLED)\n",
    "        cv2.rectangle(image, shoulder_diff_box_start, shoulder_diff_box_end, (230, 216, 173), 1)\n",
    "\n",
    "        # Deviation Box\n",
    "        deviation_box_start = (central_vertical_line_pixel_x + 5, shoulder_midpoint_pos[1] + 15 - deviation_text_size[1] - 2)\n",
    "        deviation_box_end = (deviation_box_start[0] + deviation_text_size[0] + 4, shoulder_midpoint_pos[1] + 15 + 2)\n",
    "        cv2.rectangle(image, deviation_box_start, deviation_box_end, (255, 255, 255), cv2.FILLED)\n",
    "        cv2.rectangle(image, deviation_box_start, deviation_box_end, (230, 216, 173), 1)\n",
    "\n",
    "        # Now put the text on top of the boxes\n",
    "        cv2.putText(image, shoulder_diff_text, (shoulder_diff_box_start[0], shoulder_diff_box_start[1] + shoulder_diff_text_size[1] + 2), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (139, 0, 0), 1)\n",
    "        cv2.putText(image, deviation_full_text, (deviation_box_start[0], deviation_box_start[1] + deviation_text_size[1] + 2), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (139, 0, 0), 1)\n",
    "        \n",
    "        \n",
    "        # Add text for posture\n",
    "        cv2.putText(image, f'Posture: {posture}', (10, 30), cv2.FONT_HERSHEY_COMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c73bd4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3.1 Stand front"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968c33d3",
   "metadata": {},
   "source": [
    "### 3.1.1 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d27ca8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stand_front_analysis(landmarks, mp_pose):\n",
    "    \"\"\"\n",
    "    Analyzes front-view standing posture based on landmarks.\n",
    "\n",
    "    Args:\n",
    "    - landmarks (list): List of detected pose landmarks.\n",
    "    - mp_pose (module): Mediapipe pose module for landmark references.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Returns a tuple containing the detected posture and a tuple of angle differences for ears, shoulders, hips, knees, and ankles.\n",
    "    \"\"\"\n",
    "    # Get points for ears, shoulders, hips, knees, and ankles\n",
    "    left_ear, left_shoulder, left_hip, left_knee, left_ankle = map(\n",
    "        lambda lm: get_point(landmarks, lm),\n",
    "        [mp_pose.PoseLandmark.LEFT_EAR, mp_pose.PoseLandmark.LEFT_SHOULDER, \n",
    "         mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.LEFT_KNEE, \n",
    "         mp_pose.PoseLandmark.LEFT_ANKLE])\n",
    "\n",
    "    right_ear, right_shoulder, right_hip, right_knee, right_ankle = map(\n",
    "        lambda lm: get_point(landmarks, lm),\n",
    "        [mp_pose.PoseLandmark.RIGHT_EAR, mp_pose.PoseLandmark.RIGHT_SHOULDER, \n",
    "         mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.RIGHT_KNEE, \n",
    "         mp_pose.PoseLandmark.RIGHT_ANKLE])\n",
    "\n",
    "    # Calculate joint angles\n",
    "    left_ear_angle = abs(calculate_angle([left_ear[0], 0], left_ear, right_ear))\n",
    "    right_ear_angle = abs(calculate_angle([right_ear[0], 0], right_ear, left_ear))\n",
    "\n",
    "    left_shoulder_angle = abs(calculate_angle([left_shoulder[0], 0], left_shoulder, right_shoulder))\n",
    "    right_shoulder_angle = abs(calculate_angle([right_shoulder[0], 0], right_shoulder, left_shoulder))\n",
    "\n",
    "    left_hip_angle = abs(calculate_angle([left_hip[0], 0], left_hip, right_hip))\n",
    "    right_hip_angle = abs(calculate_angle([right_hip[0], 0], right_hip, left_hip))\n",
    "\n",
    "    left_knee_angle = abs(calculate_angle([left_knee[0], 0], left_knee, right_knee))\n",
    "    right_knee_angle = abs(calculate_angle([right_knee[0], 0], right_knee, left_knee))\n",
    "\n",
    "    left_ankle_angle = abs(calculate_angle([left_ankle[0], 0], left_ankle, right_ankle))\n",
    "    right_ankle_angle = abs(calculate_angle([right_ankle[0], 0], right_ankle, left_ankle))\n",
    "\n",
    "    # Determine if joints are level using angle differences and buffer\n",
    "\n",
    "    ear_postures = [\"H.L. ear\", \"H.R. ear\"]\n",
    "    shoulder_postures = [\"H.L. shoulder\", \"H.R. shoulder\"]\n",
    "    hip_postures = [\"H.L. hip\", \"H.R. hip\"]\n",
    "    knee_postures = [\"H.L. knee\", \"H.R. knee\"]\n",
    "    ankle_postures = [\"H.L. ankle\", \"H.R. ankle\"]\n",
    "\n",
    "    posture = \"\"\n",
    "    if left_ear_angle - right_ear_angle > sml_buffer:\n",
    "        posture += sign + ear_postures[0]\n",
    "    elif right_ear_angle - left_ear_angle > sml_buffer:\n",
    "        posture += sign + ear_postures[1]\n",
    "\n",
    "    if left_shoulder_angle - right_shoulder_angle > sml_buffer:\n",
    "        posture += sign + shoulder_postures[0]\n",
    "    elif right_shoulder_angle - left_shoulder_angle > sml_buffer:\n",
    "        posture += sign + shoulder_postures[1]\n",
    "\n",
    "    if left_hip_angle - right_hip_angle > sml_buffer:\n",
    "        posture += sign + hip_postures[0]\n",
    "    elif right_hip_angle - left_hip_angle > sml_buffer:\n",
    "        posture += sign + hip_postures[1]\n",
    "\n",
    "    if left_knee_angle - right_knee_angle > sml_buffer:\n",
    "        posture += sign + knee_postures[0]\n",
    "    elif right_knee_angle - left_knee_angle > sml_buffer:\n",
    "        posture += sign + knee_postures[1]\n",
    "\n",
    "    if left_ankle_angle - right_ankle_angle > sml_buffer:\n",
    "        posture += sign + ankle_postures[0]\n",
    "    elif right_ankle_angle - left_ankle_angle > sml_buffer:\n",
    "        posture += sign + ankle_postures[1]\n",
    "\n",
    "    if posture == \"\":\n",
    "        posture = \"Correct\"\n",
    "\n",
    "    # Update posture data\n",
    "    detected_postures = posture.split(sign)\n",
    "    for detected_posture in detected_postures:\n",
    "        detected_posture = detected_posture.strip()\n",
    "        if detected_posture in ear_postures:\n",
    "            update_posture_data(\"Ear\", ear_postures, detected_posture)\n",
    "        elif detected_posture in shoulder_postures:\n",
    "            update_posture_data(\"Shoulder\", shoulder_postures, detected_posture)\n",
    "        elif detected_posture in hip_postures:\n",
    "            update_posture_data(\"Hip\", hip_postures, detected_posture)\n",
    "        elif detected_posture in knee_postures:\n",
    "            update_posture_data(\"Knee\", knee_postures, detected_posture)\n",
    "        elif detected_posture in ankle_postures:\n",
    "            update_posture_data(\"Ankle\", ankle_postures, detected_posture)\n",
    "        elif detected_posture == \"Correct\":\n",
    "            posture_data[\"Correct\"] = posture_data.get(\"Correct\", 0) + 1\n",
    "\n",
    "    return posture, (left_ear_angle - right_ear_angle, left_shoulder_angle - right_shoulder_angle, left_hip_angle - right_hip_angle, left_knee_angle - right_knee_angle, left_ankle_angle - right_ankle_angle)\n",
    "\n",
    "# Define or import calculate_angle, posture_data, update_posture_data, mp_pose, and pose_landmark before using this function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735b3cac",
   "metadata": {},
   "source": [
    "### 3.1.2 Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afb80d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stand_front_detection(image, results, posture, angles):\n",
    "    \"\"\"\n",
    "    Analyzes and annotates an image for stand front exercises.\n",
    "\n",
    "    Args:\n",
    "    - image (numpy.ndarray): The image on which to perform the analysis and annotations.\n",
    "    - results (object): The detected pose landmarks from a pose estimation model.\n",
    "    - posture (str): Description of the overall posture.\n",
    "    - angles (tuple): Contains analysis data like shoulder vertical difference,\n",
    "                                shoulder midpoint, and central vertical line position.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The annotated image with landmarks, vertical line, and deviation information.\n",
    "    \"\"\"\n",
    "    \n",
    "    if results.pose_landmarks:\n",
    "        landmark_idx = [7, 8, 11, 12, 23, 24, 25, 26, 27, 28]\n",
    "        # Draw the lines\n",
    "        for i in range(0, len(landmark_idx), 2):\n",
    "            draw_colored_connection(image, results, landmarks_to_draw[landmark_idx[i]], landmarks_to_draw[landmark_idx[i+1]])\n",
    "        for i in range(2, len(landmark_idx)-2, 2):\n",
    "            draw_colored_connection(image, results, landmarks_to_draw[landmark_idx[i]], landmarks_to_draw[landmark_idx[i+2]], color=(0, 0, 255))\n",
    "        for i in range(3, len(landmark_idx)-2, 2):\n",
    "            draw_colored_connection(image, results, landmarks_to_draw[landmark_idx[i]], landmarks_to_draw[landmark_idx[i+2]], color=(0, 0, 255))\n",
    "\n",
    "        draw_colored_connection(image, results, landmarks_to_draw[landmark_idx[0]], landmarks_to_draw[landmark_idx[2]], color=(0, 0, 255))\n",
    "        draw_colored_connection(image, results, landmarks_to_draw[landmark_idx[1]], landmarks_to_draw[landmark_idx[3]], color=(0, 0, 255))\n",
    "        draw_landmarks(image, results, landmark_idx) # Draw the specified landmarks\n",
    "        \n",
    "        joint_landmarks = [landmarks_to_draw[idx].value for idx in landmark_idx[::2]] # Draw the lines and display angles\n",
    "        draw_labeled_box(image, results, joint_landmarks, angles) # Call the draw_labeled_box function\n",
    "        \n",
    "        # Add text for posture\n",
    "        cv2.putText(image, f'Posture: {posture}', (0, 20), cv2.FONT_HERSHEY_COMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1866ff6c",
   "metadata": {},
   "source": [
    "## 3.2 Stand Side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636d94c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4081dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stand_side_analysis(landmarks, mp_pose):\n",
    "    \"\"\"\n",
    "    Analyzes side-view standing posture based on landmarks.\n",
    "\n",
    "    Args:\n",
    "    - landmarks (list): List of detected pose landmarks.\n",
    "    - mp_pose (module): Mediapipe pose module for landmark references.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Returns a tuple containing the detected posture and the left shoulder angle.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get points for ear and shoulder\n",
    "    left_ear, left_shoulder, left_hip, left_knee, left_ankle = map(\n",
    "        lambda lm: get_point(landmarks, lm),\n",
    "        [mp_pose.PoseLandmark.LEFT_EAR, mp_pose.PoseLandmark.LEFT_SHOULDER, \n",
    "         mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.LEFT_ANKLE])\n",
    "\n",
    "    # Posture Analysis\n",
    "    # Calculate shoulder angle\n",
    "    left_shoulder_angle = abs(calculate_angle([left_shoulder[0], 0], left_shoulder, left_ear))\n",
    "    \n",
    "    left_knee_angle = abs(calculate_angle(left_hip, left_knee, left_ankle))\n",
    "\n",
    "    # Determine if shoulder angle is correct\n",
    "    correct_shoulder_angle = 0  # Correct shoulder angle (ideal posture)\n",
    "    shoulder_high = left_shoulder_angle > (correct_shoulder_angle + buffer)\n",
    "\n",
    "    # Update posture condition\n",
    "    shoulder_postures = [\"Forward head\"]\n",
    "    posture = \"\"\n",
    "    if shoulder_high:\n",
    "        posture += sign + shoulder_postures[0]\n",
    "\n",
    "\n",
    "    if posture == \"\":\n",
    "        posture = \"Correct\"\n",
    "\n",
    "    # Update posture data\n",
    "    detected_posture = posture.strip(sign)\n",
    "    if detected_posture in shoulder_postures:\n",
    "        update_posture_data(\"Head\", shoulder_postures, detected_posture)\n",
    "    elif detected_posture == \"Correct\":\n",
    "        posture_data[\"Correct\"] = posture_data.get(\"Correct\", 0) + 1\n",
    "\n",
    "    return posture, (left_shoulder_angle, left_knee_angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a3ca1d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.2.2 Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00389f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stand_side_detection(image, results, posture, angles):\n",
    "    \"\"\"\n",
    "    Analyzes and annotates a side-view image of a standing posture.\n",
    "\n",
    "    Args:\n",
    "    - image (numpy.ndarray): The image on which to perform the analysis and annotations.\n",
    "    - results (object): The detected pose landmarks from a pose estimation model.\n",
    "    - posture (str): Description of the overall posture.\n",
    "    - angles (tuple): Tuple containing angles, where angles[0] is the neck angle and angles[1] is another angle, such as the knee angle.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The annotated image with neck angle and posture information.\n",
    "    \"\"\"\n",
    "    if results.pose_landmarks:\n",
    "        landmark_idx = [7, 11, 23, 25, 27]\n",
    "        # Draw the lines\n",
    "        draw_colored_connection(image, results, landmarks_to_draw[7], landmarks_to_draw[11])\n",
    "        draw_colored_connection(image, results, landmarks_to_draw[11], landmarks_to_draw[23], color=(0, 0, 255))\n",
    "        draw_colored_connection(image, results, landmarks_to_draw[23], landmarks_to_draw[25])\n",
    "        draw_colored_connection(image, results, landmarks_to_draw[25], landmarks_to_draw[27], color=(0, 0, 255))\n",
    "        \n",
    "        # Draw a vertical line across the left hip\n",
    "        left_hip_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP.value]\n",
    "        left_hip_x = int(left_hip_landmark.x * image.shape[1])\n",
    "        cv2.line(image, (left_hip_x, 0), (left_hip_x, image.shape[0]), (255, 255, 0), thickness=1)\n",
    "        \n",
    "        \n",
    "        draw_landmarks(image, results, landmark_idx) # Draw circles for specified landmarks\n",
    "            \n",
    "        joint_landmarks = [landmarks_to_draw[11].value, landmarks_to_draw[25].value] # Display angle information using a loop\n",
    "        draw_labeled_box(image, results, joint_landmarks, angles) # Call the draw_labeled_box function\n",
    "\n",
    "        # Add text for posture\n",
    "        cv2.putText(image, f'Posture: {posture}', (10, 20), cv2.FONT_HERSHEY_COMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af504e45",
   "metadata": {},
   "source": [
    "# Run Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc67bfa1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheun\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e931f69b-75f2-4a92-8ade-e9f6a2fb72c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
